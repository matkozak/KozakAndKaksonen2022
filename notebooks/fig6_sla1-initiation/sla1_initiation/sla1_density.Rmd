---
title: "Sla1 patch density in Ede1 internal mutants"
date: "Last compiled on `r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    code_download: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE,
                      dpi = 96, fig.width = 4, fig.height = 3)
```

```{r libs}
library(tidyverse)
library(ggbeeswarm)
library(ggsignif)
library(broom)
library(rstatix)
library(knitr)
library(multcompView)
```

```{r load}
# Load data generated by cleanup notebook
rm(list = ls())
load('data/sla1_density.RData')
```

```{r theme}
# Custom ggplot2 theme
# --------------------

# minimal theme with border
# based on theme_linedraw without the grid lines
# also trying to remove all backgrounds and margins
# the aim is to make it as easy as possible to edit in illustrator

theme_clean <- function(base_size = 11, base_family = "",
                        base_line_size = base_size / 22,
                        base_rect_size = base_size / 22) {
  theme_linedraw(
    base_size = base_size,
    base_family = base_family,
    base_line_size = base_line_size,
    base_rect_size = base_rect_size
  ) %+replace%
    theme(
      # no grid and no backgrounds if I can help it
      legend.background =  element_blank(),
      panel.background = element_blank(),
      panel.grid = element_blank(),
      plot.background = element_blank(),
      plot.margin = margin(0, 0, 0, 0),
      complete = TRUE
    )
}

# Set default theme
# -----------------
theme_set(theme_clean(base_size = 12, base_family = "Myriad Pro"))

# Create a ggsave wrapper
# -----------------------

# This way we can set a default size and device for all plots
my_ggsave <- function(filename, plot = last_plot(),
                      device = cairo_pdf, units = "mm",
                      width = 100, height = 80, ...){
  ggsave(filename = filename, plot = plot,
         device = device, units = units,
         height = height, width = width,  ...)
  }
```

```{r functions}
# couple of small functions for extracting comparisons
# into a format understandable by ggplot

#' Add letter group labels generated by Tukey's HSD
#'
#' This function performs ANOVA and Tukey's HSD,
#' extracts the letter labels and attaches them
#' to the original data.
#'
#' @param x: df or tibble, the data (long format!)
#' @param yvar: chr, name of the dependent variable
#' @param xvar: chr, name of the independent variable
#' @param alpha: dbl, confidence level passed on to Tukey's test
#'
add_tukey_labels <- function(x, yvar, xvar, alpha = 0.95){
  aov_form <- formula(paste(yvar, '~', xvar))
  anova <- aov(formula = aov_form, data = x)
  tukey <- TukeyHSD(anova, which = xvar, conf.level = alpha)
  # Extract labels and factor levels from Tukey post-hoc 
  x_labels <- as_tibble(
    multcompLetters4(anova, tukey)[[xvar]]$Letters,
    rownames = xvar
    )
  
  if (is.factor(x[[xvar]])) {
    x_labels[[xvar]] <- factor(
      x_labels[[xvar]], levels = levels(x[[xvar]])
    )
  }
  
  x_labels <- rename(x_labels, tukey_group = value)
  x <- left_join(x, x_labels, by = xvar)
  
  return(x)
  }


#' Extract comparisons from rstatix tidy tests
#' 
#' This function subsets the selected comparisons in a Tukey,
#' Dunn or similar test done by rstatix.
#' It converts groups to a list of vectors that can be passed to geom_signif
#'
#'
#' @param x: df or tibble, the comparison results
#' @param rows: integer vector, the rows with desired comparisons
extract_comparisons <- function(x, rows){
  x_subset <- x[rows,] %>%
    .[nrow(.):1,]
  
  x_comparisons <- x_subset %>%
    select(group1, group2) %>%
    t() %>%
    as.data.frame() %>%
    as.list
  x_annotations <- x_subset$p.adj.signif %>%
    as.vector()
  
  significance <- list(
    comparisons = x_comparisons,
    annotations = x_annotations
  )
  
  return(significance)
}
```

# {.tabset .tabset-pills}

## Experiment

### Rationale

The aim of the experiment is to determine patch initiation rates 
in Ede1 internal domain deletion mutants.
We looked at the patch density and lifetimes of late coat protein Sla1 
in Ede1 mutants lacking all or some of the central region.
This notebook is devoted to the Sla1 patch density.

### Illumination settings

I acquired all data on the Olympus IX81
equipped with a 100x/1.49 objective,
using the X-Cite 120PC lamp at 50% intensity
(except dataset #2, see below)
and 400 ms exposure for illumination.
Light was filtered through a U-MGFPHQ filter cube.
I acquired stacks of 26 planes 
with a step size of 0.2 microns.

### Image processing

Individual non-budding cells were cropped from fields of view.
Patch numbers were extracted using Python function `count_patches`
from my personal package `mkimage`
containing a set of wrappers for `scikit-image` functions.
Briefly, the images were median-filtered with a 5 px disk brush,
and the filtered images were subtracted from the originals
to subtract local background.
The background-subtracted images were thresholded using the Yen method.
The thresholded images were eroded using the number of non-zero
neighbouring pixels in 3D as the erosion criterion.
The spots were counted using skimage.measure.label() function with 2-connectivity.

Cross-section area was obtained by 
median-filtering of the stack with 10px disk brush, 
calculating the maximum projection image, 
thresholding using Otsu's algorithm,
and using skimage.measure.regionprops() to measure area.
Note that these are pixel counts of *cross-section* area. 
To determine the total surface area, 
I assumed that an unbudded cell is spherical
(suface area is four times the cross-section area).

This call to `site_counter` was used to process all datasets:

```
process_folder(path, median_radius = 5, erosion_n = 1, con = 2,
                   method = Yen, mask = False, loop = False, save_images = True)
```

`data_cleanup.Rmd` was used to gather all output into tidy data frames
with no further modifications.

### List of strains used

```{r strains}
kable(strains)
```

### Addendum on replicates

Despite my best intentions, there were some discrepancies
in the illumination settings between datasets.
Datasets #1 and #2 were acquired at 100% lamp power,
but #1 had a 50% ND filter inserted in the light path and #2 did not,
which I did not know at the time.

As a result, the overall signal in dataset #2 was brighter,
but there was more bleaching of the further parts of the stack.
This might have resulted in undercounting of some patches at the bottom.

With datasets #3 and #4 I was careful not to repeat the same mistake
and acquired everything at 50% lamp power.

Therefore datasets 1, 3 and 4 could be seen as 'canonical' independent repeats.
However, #2 does not ultimately seem like an outlier,
so I included it in the final analysis.

## Per-dataset summary {.tabset}

### Patch number and area

```{r nums_dataset}
# means and SDs of number of patches and area
sla1_density %>%
  group_by(ede1, dataset) %>%
  summarise(n = n(),
            across(c(patches, area), list(mean = mean, sd = sd,
                                          se = ~sd(.x) / sqrt(n())))) %>%
  kable()
```

### Sla1 density

We can combine the patch number and area into $density = \frac{patches}{area}$,
calculated individually for each cell.
We can summarise the data for each Ede1 mutant in each dataset:

```{r density}
sla1_density_stats <- sla1_density %>%
  group_by(ede1, dataset) %>%
  summarise(n = n(),
            across(density,
                   list(mean = mean, sd = sd, 
                        se = ~ sd(.x) / sqrt(n),
                        median = median, mad = mad)),
            .groups = 'drop')

sla1_density_stats %>% kable()
```

## Plots {.tabset}

```{r density.scatter}
plot_blank <- ggplot(sla1_density_stats,
                     aes(x = ede1, y = density_mean)) +
                         #shape = dataset, fill = dataset))+
  labs(title = NULL, x = 'Ede1', y = expression( "Sla1 patches/Âµm"^2)) +
  scale_y_continuous(breaks = seq(0.0, 1.0, 0.1)) +
  scale_shape_manual(values = c(21:25)) +
  scale_color_brewer(palette = 'Set2') +
  scale_fill_brewer(palette = 'Set2')

plot_scatter <- plot_blank +
  geom_quasirandom(inherit.aes = F, data = sla1_density,
                   aes(x = ede1, y = density,
                       shape = dataset,# colour = dataset
                       ),
                   colour = 'grey75',# shape = 1,
                   show.legend = F, size = 0.8
                   )

plot_violin <- plot_blank + 
  geom_violin(inherit.aes = F,
              data = sla1_density, aes(x = ede1, y = density),
              colour = 'grey75', fill = 'transparent'
              )
```

### SuperPlots

I have chosen to show this data using the 
[SuperPlot](https://doi.org/10.1083/jcb.202001064) style.
Each point shows density of Sla1-EGFP patches in an individual cell.

Big colour points show mean measurements from four independent repeats.

Range is mean +/- SD, calculated based on the four independent repeat means.

#### Beeswarm

```{r}
plot_super <- plot_scatter +
  geom_quasirandom(aes(shape = dataset, fill = dataset),
                   show.legend = F,
                   width = 0.3, size = 2)+
  stat_summary(fun = mean, geom = 'crossbar',
               width = 0.5, fatten = 1)+
  stat_summary(fun.data = 'mean_sdl',
               fun.args = list(mult = 1), 
               geom = 'errorbar', width = 0.2)
  
print(plot_super)
my_ggsave('figures/density_super.pdf')

```

#### Violin

```{r}
plot_super_violin <- plot_violin +
  geom_quasirandom(aes(shape = dataset, fill = dataset),
                   show.legend = F,
                   width = 0.3, size = 2)+
  stat_summary(fun = mean, geom = 'crossbar',
               width = 0.5, fatten = 1)+
  stat_summary(fun.data = 'mean_sdl',
               fun.args = list(mult = 1),
               geom = 'errorbar', width = 0.2)

print(plot_super_violin)
my_ggsave('figures/density_super_violin.pdf')
```

### With significance

Let's add significance stars based on Tukey's test.

```{r tests}
tukey <- tukey_hsd(sla1_density_stats, density_mean ~ ede1,
                   ordered = TRUE)
```

```{r}
significance <- extract_comparisons(tukey, c(1:4, 10))

plot_super_signif <- plot_super +
  geom_signif(comparisons = significance$comparisons,
              annotations = significance$annotations,
              step_increase = 0.03,
              tip_length = 0.01, vjust = 0.8,
              margin_top = -0.1)
print(plot_super_signif)
my_ggsave('figures/density_super_signif.pdf')
```

This is only a subset of comparisons and it's already cluttered.
The alternative is...

#### Letter annotations

In this view, groups sharing at least one letter are not significant
at a chosen $\alpha$ (here, 95%).

Pros:

  * less cluttered and simpler to read (5 groups = 10 comparisons)
  * focus away from p-values; provide a binary decision on the null hypothesis
  
Cons:

  * cannot distinguish different confidence levels

```{r}
sla1_density_stats <- sla1_density_stats %>%
  add_tukey_labels('density_mean', 'ede1')
```

```{r}
plot_super_letters <- plot_super +
  geom_text(data = sla1_density_stats,
            aes(label = tukey_group), y = Inf, vjust = 1.2)
  #stat_summary(aes(label = tukey_group),
  #             fun.y = Inf,
  #             geom = 'text', na.rm = T, vjust = -0.5,
  #             #fun.args = list(err = errors, mult = error_range)
  #             )
print(plot_super_letters)
my_ggsave('figures/density_super_letters.pdf')
```

## Hypothesis testing {.tabset}

### Assumptions

ANOVA and similar parametric tests 
assume that the errors are normally distributed,
with homogeneous variances,
and that the samples are independent.

We will test the null hypothesis that mean Sla1 density is the same
across different Ede1 strains.
We will use repeat-level data for the tests
to account for experimental variability.

#### Normality

From the plots it looks like the underlying data is 'normal enough',
considering that ANOVA can tolerate some departure from normality.
We can check the normality of residuals used in the model later, but it might
still be interesting to know how normal the underlying data is overall.

If we do a formal test (Shapiro-Wilkes):

```{r}
sla1_density %>%
  group_by(ede1) %>%
  summarise(n = n(),
            shapiro.p = tidy(shapiro.test(density))$p.value, 
            .groups = 'drop') %>%
  kable()
```

Q-Q plots:

```{r fig.height=6, fig.width=8}
sla1_density %>%
  ggplot(aes(sample = density))+
  facet_wrap('ede1', scales = 'free')+          
  labs(colour = 'Dataset', shape = 'Dataset')+
  stat_qq(shape = 1)+
  stat_qq_line()
```

The data looks quite normal.

#### Homoscedasticity

4 points per group is probably enough to assess
whether the variance is similar in the repeat-level data.
Levene's test:

```{r}
sla1_density_stats %>%
  levene_test(density_mean ~ ede1) %>%
  kable()
```

Levene's cannot reject the null here (variance does not differ between groups).

### One-way ANOVA 

Given the null of mean equality, 
what is the likelihood of obtaining these results?

```{r}
anova <- aov(density_mean ~ ede1, data = sla1_density_stats)
tidy(anova) %>% kable()
```

One-way ANOVA rejects the null with $p = 10^{-7}$.

#### Diagnostic plots

```{r}
hist(residuals(anova))
plot(anova) 
```

The residuals look approximately normally distributed (histogram, Q-Q plot)
with similar variance (Residuals vs. Fitted, grouped by factor).

### Post-hoc test (Tukey)

Following the rejection of the null by ANOVA, we can use Tukey-Kramer
to check pariwse comparisons. 

```{r}
tukey %>%
  kable()
```

Two comparisons do not produce statistically significant differences:

* between ede1âPQ and ede1âCC
* between ede1âPQCC and ede1â

For all other groups, $p < 0.05$ (at least);
for all comparisons with wild type $p < 0.001$.

## Overall summary

Summary statistics for all experiments, derived from *mean values*
of N independent repeats.

### Final estimates

Final estimates with lower / upper 95% confidence intervals and a comparison
to wild type (in %). `half_ci` is just the error for writing CI ranges
in the format mean +/- error.

```{r}
wt_mean <- sla1_density_stats %>%
  filter(ede1 == 'wt') %>%
  pull(density_mean) %>%
  mean()

density_ci <- sla1_density_stats %>%
  group_by(ede1)%>%
  summarise(mean_cl_normal(density_mean)) %>%
  rename(mean = y, lower = ymin, upper = ymax) %>%
  mutate(proc_wt = round(100 * mean / wt_mean),
         half_ci = (upper - lower) / 2) 

kable(density_ci, digits = 3)
```

### Conclusions

1. All mutations cause a significant reduction in patch density from wild type
2. Ede1âPQCC is indistinguishable from full Ede1 deletion, 
  causes ~50% reduction in density
3. Individual PQ / CC deletions have intermediate defects

### More statistics

```{r}
sla1_density_stats %>%
  group_by(ede1)%>%
  summarise(N = n(),
            across(density_mean,
                   list(mean = mean, sd = sd,
                        se = ~ sd(.x) / sqrt(n()),
                        median = median, mad = mad),
                       .names = '{.fn}'),
            .groups = 'drop') %>%
  kable(digits = 3)
```

### More statistics (observation-level)

So far we have mostly looked at the statistics 
derived from experiment-level means.
For completeness, the table below
reports number of observations and density statistic 
derived from pooled observations from all repeats,
in each group:

```{r}
sla1_density %>%
  group_by(ede1)%>%
  summarise(n = n(),
            across(density,
                   list(mean = mean, sd = sd,
                        se = ~ sd(.x) / sqrt(n()),
                        median = median, mad = mad
                        #, quant = ~quantile(.x, c(0.25, 0.5, 0.75))
                        ),
                       .names = '{.fn}'),
            pivot_wider(enframe(quantile(density, c(0.25, 0.75)))),
            .groups = 'drop') %>%
  
  kable(digits = 3)
```

## Source data

### .csv

```{r echo=FALSE}
xfun::embed_file('data/sla1_density.csv')
```

### .RData

```{r echo=FALSE}
xfun::embed_file('data/sla1_density.RData')
```

## Session info

```{r session, message=TRUE}
sessionInfo()
```
